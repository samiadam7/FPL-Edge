{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/samiadam/Repositories/Projects/FPL_Project'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import requests\n",
    "import time\n",
    "import csv\n",
    "import os\n",
    "\n",
    "os.chdir('/Users/samiadam/Repositories/Projects/FPL_Project/')\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['expected_assists',\n",
       " 'expected_goal_involvements',\n",
       " 'expected_goals',\n",
       " 'expected_goals_conceded',\n",
       " 'starts']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df20 = pd.read_csv(\"./data/2020-21/merged_gw.csv\")\n",
    "df24 = pd.read_csv(\"./data/2024-25/merged_gw.csv\")\n",
    "\n",
    "[col for col in df24.columns if col not in df20.columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FPL Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data():\n",
    "    url = \"https://fantasy.premierleague.com/api/bootstrap-static/\"\n",
    "    response = \"\"\n",
    "    \n",
    "    while response == \"\":\n",
    "        try:\n",
    "            response = requests.get(url)\n",
    "        except:\n",
    "            time.sleep(5)\n",
    "    \n",
    "    if response.status_code != 200:\n",
    "        raise Exception(f\"Response Code: {response.status_code}\")\n",
    "    \n",
    "    data = json.loads(response.content)\n",
    "    return data\n",
    "\n",
    "def get_fixture_data():\n",
    "    url = \"https://fantasy.premierleague.com/api/fixtures/\"\n",
    "\n",
    "    response = \"\"\n",
    "    while response == \"\":\n",
    "        try:\n",
    "            response = requests.get(url)\n",
    "        except:\n",
    "            time.sleep(5)\n",
    "\n",
    "    if response.status_code != 200:\n",
    "        raise Exception(f\"Response Code: {response.status_code}\")\n",
    "\n",
    "    data = json.loads(response.text)\n",
    "    return data\n",
    "\n",
    "def get_individual_data(id):\n",
    "    base_url = \"https://fantasy.premierleague.com/api/element-summary/\"\n",
    "    url = base_url + str(id) + \"/\"\n",
    "    response = \"\"\n",
    "    \n",
    "    while response == \"\":\n",
    "        try:\n",
    "            response = requests.get(url)\n",
    "        except:\n",
    "            time.sleep(5)\n",
    "            \n",
    "    if response.status_code != 200:\n",
    "        raise Exception(f\"Response Code: {response.status_code}\")\n",
    "    \n",
    "    data = json.loads(response.text)\n",
    "    return data\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parsing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_stat_names(stat_dict):\n",
    "    stat_names = []\n",
    "    for key in stat_dict.keys():\n",
    "        stat_names += [key]\n",
    "\n",
    "    return stat_names\n",
    "\n",
    "def parse_players(list_of_players, base_path):\n",
    "    stat_names = extract_stat_names(list_of_players[0])\n",
    "\n",
    "    file_name = os.path.join(base_path,  \"players_raw.csv\")\n",
    "    os.makedirs(os.path.dirname(base_path), exist_ok=True)\n",
    "    \n",
    "    f = open(file_name, \"w+\", encoding= \"utf8\", newline= \"\")\n",
    "    w = csv.DictWriter(f, sorted(stat_names))\n",
    "\n",
    "    w.writeheader()\n",
    "    for player in list_of_players:\n",
    "        w.writerow({k:str(v).encode('utf-8').decode('utf-8') for k, v in player.items()})\n",
    "        \n",
    "def parse_fixtures(data, base_path):\n",
    "    fixtures_df = pd.DataFrame.from_records(data)\n",
    "    fixtures_df.to_csv(os.path.join(base_path, \"fixtures.csv\"), index= False)\n",
    "    \n",
    "def parse_team_data(data, base_path):\n",
    "    teams_df = pd.DataFrame.from_records(data)\n",
    "    teams_df.to_csv(os.path.join(base_path, \"teams.csv\"), index= False)\n",
    "\n",
    "def parse_player_gw_history(gw_history_list, base_path, name, id):\n",
    "    if gw_history_list:\n",
    "        stat_names = extract_stat_names(gw_history_list[0])\n",
    "        file_path = os.path.join(base_path, f\"{name}_{id}\", \"gw.csv\")\n",
    "        os.makedirs(os.path.dirname(file_path), exist_ok= True)\n",
    "\n",
    "        with open(file_path, \"w+\", encoding= \"utf-8\", newline= \"\") as file:\n",
    "            w = csv.DictWriter(file, sorted(stat_names))\n",
    "            w.writeheader()\n",
    "            w.writerows(gw_history_list)\n",
    "            \n",
    "def parse_player_season_history(player_hist_list, base_path, name, id):\n",
    "    if player_hist_list:\n",
    "        stat_names = extract_stat_names(player_hist_list[0])\n",
    "        file_path = os.path.join(base_path, f\"{name}_{id}\", \"history.csv\")\n",
    "        os.makedirs(os.path.dirname(file_path), exist_ok= True)\n",
    "        \n",
    "        with open(file_path, \"w+\", encoding= \"utf-8\", newline= \"\") as file:\n",
    "            w = csv.DictWriter(file, sorted(stat_names))\n",
    "            w.writeheader()\n",
    "            w.writerows(player_hist_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_players(file_name, base_path):    \n",
    "    headers = ['first_name', 'second_name', 'goals_scored', 'assists', 'total_points', 'minutes', 'goals_conceded', 'creativity', 'influence', 'threat', 'bonus', 'bps', 'ict_index', 'clean_sheets', 'red_cards', 'yellow_cards', 'selected_by_percent', 'now_cost', 'element_type']\n",
    "\n",
    "    raw = open(base_path + file_name, \"r+\", encoding= \"utf-8\")\n",
    "    out_name = base_path + \"players_clean.csv\"\n",
    "    clean = open(out_name, \"w+\", encoding= \"utf-8\", newline = \"\")\n",
    "\n",
    "    reader = csv.DictReader(raw)\n",
    "    writer = csv.DictWriter(clean, headers, extrasaction= \"ignore\")\n",
    "    writer.writeheader()\n",
    "    for line in reader:\n",
    "        if line['element_type'] == '1':\n",
    "            line['element_type'] = 'GK'\n",
    "        elif line['element_type'] == '2':\n",
    "            line['element_type'] = 'DEF'\n",
    "        elif line['element_type'] == '3':\n",
    "            line['element_type'] = 'MID'\n",
    "        elif line['element_type'] == '4':\n",
    "            line['element_type'] = 'FWD'\n",
    "        else:\n",
    "            print(\"Oh boy\")\n",
    "        writer.writerow(line)\n",
    "        \n",
    "def id_players(file_name, base_path):\n",
    "    headers = [\"first_name\", \"second_name\", \"id\"]\n",
    "    raw = open(base_path + file_name, \"r+\", encoding= \"utf-8\")\n",
    "    clean_name = base_path + \"player_idlist.csv\"\n",
    "    os.makedirs(os.path.dirname(clean_name), exist_ok=True)\n",
    "\n",
    "    clean = open(clean_name, \"w+\", encoding= \"utf-8\", newline= \"\")\n",
    "    reader = csv.DictReader(raw)\n",
    "    writer = csv.DictWriter(clean, headers, extrasaction= \"ignore\")\n",
    "\n",
    "    writer.writeheader()\n",
    "    for line in reader:\n",
    "        writer.writerow(line)\n",
    "        \n",
    "def get_player_ids(base_path):\n",
    "    file_name = base_path + \"player_idlist.csv\"\n",
    "\n",
    "    file = open(file_name, \"r+\", encoding= \"utf-8\")\n",
    "    reader = csv.DictReader(file)\n",
    "    player_ids = {}\n",
    "\n",
    "    for line in reader:\n",
    "        id = line[\"id\"]\n",
    "        name = line[\"first_name\"] + \"_\" + line[\"second_name\"].replace(\" \", \"_\")\n",
    "        player_ids[id] = name\n",
    "        \n",
    "    return player_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "season = \"2024-25\"\n",
    "base_path = \"/Users/samiadam/Repositories/Projects/FPL_Project/data/\" + season + \"/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_teams(directory):\n",
    "    teams = {}\n",
    "    path = directory + \"/teams.csv\"\n",
    "    \n",
    "    with open(path, \"r\") as file_in:\n",
    "        reader = csv.DictReader(file_in)\n",
    "        for row in reader :\n",
    "            teams[int(row[\"id\"])] = row[\"name\"]\n",
    "    \n",
    "    return teams\n",
    "\n",
    "def get_fixtures(directory):\n",
    "    fix_home = {}\n",
    "    fix_away = {}\n",
    "    \n",
    "    with open(os.path.join(directory, \"fixtures.csv\"), \"r\") as file_in:\n",
    "        reader = csv.DictReader(file_in)\n",
    "        for row in reader:\n",
    "            fix_home[int(row['id'])] = int(row['team_h'])\n",
    "            fix_away[int(row['id'])] = int(row['team_a'])\n",
    "            \n",
    "    return fix_home, fix_away\n",
    "\n",
    "def get_positions(directory):\n",
    "    positions = {}\n",
    "    names = {}\n",
    "    pos_dict = {'1': \"GK\", '2': \"DEF\", '3': \"MID\", '4': \"FWD\"}\n",
    "    \n",
    "    with open(directory + \"/players_raw.csv\", 'r',encoding=\"utf-8\") as file_in:\n",
    "        reader = csv.DictReader(file_in)\n",
    "        for row in reader:\n",
    "            positions[int(row['id'])] = pos_dict[row['element_type']] \n",
    "            names[int(row['id'])] = row['first_name'] + ' ' + row['second_name']\n",
    "    \n",
    "    return names, positions\n",
    "\n",
    "def collect_gw(base_directory, output_dir, gw):\n",
    "    rows = []\n",
    "    fieldnames = []\n",
    "\n",
    "    fix_home, fix_away = get_fixtures(base_directory)\n",
    "    teams = get_teams(base_directory)\n",
    "    player_names, player_positions = get_positions(base_directory)\n",
    "\n",
    "    for root, dirs, files in os.walk(base_directory + \"players/\"):\n",
    "        for file in files:\n",
    "            if file == \"gw.csv\":\n",
    "                path = os.path.join(root, file)\n",
    "                \n",
    "                with open(path, \"r\") as file_in:\n",
    "                    reader = csv.DictReader(file_in)\n",
    "                    fieldnames = reader.fieldnames\n",
    "\n",
    "                    for row in reader:\n",
    "                        if int(row['round']) == gw:\n",
    "                            id = int(os.path.basename(root).split('_')[-1])\n",
    "                            name = player_names[id]\n",
    "                            position = player_positions[id]\n",
    "                            fixture = int(row['fixture'])\n",
    "                            if row['was_home'] == True or row['was_home'] == \"True\":\n",
    "                                row['team'] = teams[fix_home[fixture]]\n",
    "                            else:\n",
    "                                row['team'] = teams[fix_away[fixture]]\n",
    "                            row['name'] = name\n",
    "                            row['position'] = position\n",
    "                            rows += [row]\n",
    "\n",
    "    fieldnames = ['name', 'position', 'team', 'xP'] + fieldnames\n",
    "\n",
    "    os.makedirs(output_dir, exist_ok= True)\n",
    "    with open(os.path.join(output_dir, \"gw_\" + str(gw) + \".csv\"), \"w+\") as out_file:\n",
    "        w = csv.DictWriter(out_file, fieldnames= fieldnames)\n",
    "        w.writeheader()\n",
    "        w.writerows(rows)\n",
    "        \n",
    "def collect_all_gws(base_directory, output_dir, current_gw):\n",
    "    for gw in range(1, current_gw):\n",
    "        collect_gw(base_directory, output_dir, gw)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "season = \"2024-25\"\n",
    "base_path = \"/data/\" + season + \"/\"\n",
    "\n",
    "\n",
    "def global_scraper(season: str):\n",
    "    print(\"Scraping Data \\n\")\n",
    "    overall_start_time = time.time()\n",
    "    \n",
    "    # Setting vars\n",
    "    base_path = \"./data/\" + season + \"/\"\n",
    "    \n",
    "    # Getting Data\n",
    "    print(\"Getting data...\", end= \" \")\n",
    "    start = time.time()\n",
    "    \n",
    "    data = get_data()\n",
    "    end = time.time()\n",
    "    \n",
    "    elapsed_time = end - start\n",
    "    print(f\"DONE ({elapsed_time:.2f} seconds)\")\n",
    "\n",
    "    # Parsing Data\n",
    "    print(\"Parsing Data...\", end= \" \")\n",
    "    start = time.time()\n",
    "    parse_players(data[\"elements\"], base_path)\n",
    "        \n",
    "    gw_num = 0\n",
    "    events = data[\"events\"]\n",
    "    for event in events:\n",
    "        if event[\"is_current\"] == True:\n",
    "            gw_num = event[\"id\"]\n",
    "            break\n",
    "    \n",
    "    end = time.time()\n",
    "    elapsed_time = end - start\n",
    "    print(f\"DONE ({elapsed_time:.2f} seconds)\")\n",
    "            \n",
    "    # Cleaning Data\n",
    "    print(\"Cleaning Summary Data...\", end= \" \")\n",
    "    start = time.time()\n",
    "    \n",
    "    clean_players(\"players_raw.csv\", base_path)\n",
    "    \n",
    "    end = time.time()\n",
    "    elapsed_time = end - start\n",
    "    print(f\"DONE ({elapsed_time:.2f} seconds)\")\n",
    "\n",
    "    # Fixtures\n",
    "    print(\"Getting Fixtures Data...\", end= \" \")\n",
    "    start = time.time()\n",
    "    \n",
    "    fixture_data = get_fixture_data()\n",
    "    parse_fixtures(fixture_data, base_path)\n",
    "    \n",
    "    end = time.time()\n",
    "    elapsed_time = end - start\n",
    "    print(f\"DONE ({elapsed_time:.2f} seconds)\")\n",
    "\n",
    "    # Team Data\n",
    "    print(\"Getting Team Data...\", end= \" \")\n",
    "    start = time.time()\n",
    "    \n",
    "    team_data = data[\"teams\"]\n",
    "    parse_team_data(team_data, base_path)\n",
    "\n",
    "    end = time.time()\n",
    "    elapsed_time = end - start\n",
    "    print(f\"DONE ({elapsed_time:.2f} seconds)\")\n",
    "\n",
    "    # Player Data\n",
    "    print(\"Getting Player Data...\", end= \" \")\n",
    "    start = time.time()\n",
    "    \n",
    "    id_players(\"players_raw.csv\", base_path)\n",
    "    player_ids = get_player_ids(base_path)\n",
    "\n",
    "    player_base_path = base_path + 'players/'\n",
    "    gw_base_path = base_path + 'gws/'\n",
    "\n",
    "    # num_players = len(data[\"elements\"]) idk if needed\n",
    "    \n",
    "    # Player Individual Data\n",
    "    for id, name in player_ids.items():\n",
    "        player_data = get_individual_data(id)\n",
    "        parse_player_season_history(player_data[\"history_past\"], player_base_path, name, id)\n",
    "        parse_player_gw_history(player_data[\"history\"], player_base_path, name, id)\n",
    "\n",
    "    end = time.time()\n",
    "    elapsed_time = end - start\n",
    "    print(f\"DONE ({elapsed_time:.2f} seconds)\")\n",
    "\n",
    "    # Gameweek Data\n",
    "    if gw_num > 0:\n",
    "        print(\"Getting GW Data...\", end= \"\")\n",
    "        start = time.time()\n",
    "        \n",
    "        collect_gw(base_path, gw_base_path, gw_num)\n",
    "        \n",
    "        end = time.time()\n",
    "        elapsed_time = end - start\n",
    "        print(f\"DONE ({elapsed_time:.2f} seconds)\")\n",
    "        \n",
    "        print(\"Merging GW Data... \", end= \" \")\n",
    "        start = time.time()\n",
    "        \n",
    "        collect_all_gws(base_path, gw_base_path, gw_num)\n",
    "        \n",
    "        end = time.time()\n",
    "        elapsed_time = end - start\n",
    "        print(f\"DONE ({elapsed_time:.2f} seconds)\")\n",
    "        \n",
    "    overall_elapsed_time = time.time() - overall_start_time\n",
    "    print(f\"\\nGlobal scraper completed in {overall_elapsed_time:.2f} seconds.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FBREF Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from requests.exceptions import HTTPError\n",
    "import requests\n",
    "import time\n",
    "\n",
    "def get_individual_player_data(fbref_id, fbref_name):\n",
    "    fbref_name_link = fbref_name.replace(\" \", \"-\")\n",
    "    link = f\"https://fbref.com/en/players/\" + fbref_id + \"/matchlogs/2024-2025/\" +  fbref_name_link + \"-Match-Logs\"\n",
    "    \n",
    "    try:\n",
    "        \n",
    "        print(f\"Fetching data for {fbref_name}\")\n",
    "        \n",
    "        response = requests.get(link)\n",
    "        print(response.text)\n",
    "        response.raise_for_status()\n",
    "        all_performances_df = pd.read_html(response.content, attrs= {\"id\": \"matchlogs_all\"})[0]\n",
    "        all_performances_df.columns = [' '.join(col).strip() if not col[0].startswith(\"Unnamed\") else col[1] for col in all_performances_df.columns.values]\n",
    "        \n",
    "        prem_performances_df = all_performances_df[all_performances_df[\"Comp\"] == \"Premier League\"].copy()\n",
    "        prem_performances_df.loc[:, \"name\"] = fbref_name\n",
    "        \n",
    "    except HTTPError as e:\n",
    "        if response.status_code == 429:\n",
    "            wait_time = int(response.headers.get(\"Retry-After\", 10))\n",
    "            print(f\"Status Code: 429. Retrying in {wait_time} seconds...\")\n",
    "            \n",
    "            time.sleep(wait_time)\n",
    "            attempt +=1\n",
    "            \n",
    "        else:\n",
    "            raise e\n",
    "    \n",
    "    except Exception as e:\n",
    "        raise e\n",
    "    \n",
    "    return prem_performances_df\n",
    "\n",
    "    \n",
    "def collect_players_data(df, call_rate= 9.5):\n",
    "    if call_rate > 10:\n",
    "        raise Exception(\"Call rate too high. It must be below 10.\")\n",
    "    \n",
    "    wait_time = 60/call_rate\n",
    "    \n",
    "    df_list = []\n",
    "    for idx, row in df.head(1).iterrows():\n",
    "        fbref_id = row[\"id_fbref\"]\n",
    "        fbref_name = row[\"name_fbref\"]\n",
    "        \n",
    "        player_df = get_individual_player_data(fbref_id, fbref_name)\n",
    "        df_list.append(player_df)\n",
    "        \n",
    "        time.sleep(wait_time)\n",
    "    \n",
    "    return df_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from fuzzywuzzy import process\n",
    "import unicodedata\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "\n",
    "def remove_special_letters(text):\n",
    "    normalized_text = unicodedata.normalize('NFKD', text)\n",
    "    return ''.join([c for c in normalized_text if not unicodedata.combining(c)])\n",
    "\n",
    "def fuzzy_match(name, choices, threshold, scorer=process.extractOne):\n",
    "    match, score = scorer(name, choices)\n",
    "    return match if score >= threshold else np.NaN\n",
    "\n",
    "def sorted_fuzzy_match(name, choices, scorer=process.extract):\n",
    "    matches = scorer(name, choices)\n",
    "    return sorted(matches, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "def load_dfs(fbref_id_path, fpl_id_path):\n",
    "    # Load the files\n",
    "    fbref_ids = pd.read_csv(fbref_id_path)\n",
    "    fpl_ids = pd.read_csv(fpl_id_path)\n",
    "\n",
    "    fpl_ids['full_name_abbr'] = fpl_ids['first_name'].str.split(\" \").str[0] + \" \" + fpl_ids[\"second_name\"].str.split(\" \").str[-1]\n",
    "    fpl_ids['full_name_full'] = fpl_ids[\"first_name\"] + \" \" + fpl_ids[\"second_name\"]\n",
    "    fbref_ids[['first_name', 'second_name']] = fbref_ids['name'].str.split(' ',n= 1, expand=True)\n",
    "    \n",
    "    return fbref_ids, fpl_ids\n",
    "\n",
    "def check_name_match(df, fbref_df):\n",
    "    \n",
    "    matched_indices = []\n",
    "\n",
    "    for idx, row in df[~df[\"fuzzy_match\"].isna()].iterrows():\n",
    "        full_name = row[\"full_name_full\"]\n",
    "        match = row[\"fuzzy_match\"]\n",
    "        print(f\"{full_name}: {match}\")\n",
    "        agree = input(\"Do they match? (Press Enter for yes):\\n\")\n",
    "        \n",
    "        if agree.lower() == \"\": \n",
    "            matching_ids = fbref_df[fbref_df[\"name\"] == match][\"id\"]\n",
    "            if not matching_ids.empty:\n",
    "                df.at[idx, \"id_fbref\"] = matching_ids.iloc[0]\n",
    "                matched_indices.append(idx)\n",
    "        else:\n",
    "            df.at[idx, \"fuzzy_match\"] = np.NaN\n",
    "\n",
    "def map_name_match(df, fbref_df):\n",
    "    \n",
    "    matched_indices = []\n",
    "\n",
    "    for idx, row in df[~df[\"fuzzy_match\"].isna()].iterrows():\n",
    "        match = row[\"fuzzy_match\"]\n",
    "        \n",
    "        matching_ids = fbref_df[fbref_df[\"name\"] == match][\"id\"]\n",
    "        if not matching_ids.empty:\n",
    "            df.at[idx, \"id_fbref\"] = matching_ids.iloc[0]\n",
    "            matched_indices.append(idx)\n",
    "\n",
    "    df.update(df.loc[matched_indices])\n",
    "    return df\n",
    "\n",
    "def sift_names(df, fbref_df, level, name):\n",
    "    print(f\"\\n{level.title()} Sift...\")\n",
    "    matched_indices = []\n",
    "    missing_df = df[df[\"fuzzy_match\"].isna()]\n",
    "    \n",
    "    for i, (idx, row) in enumerate(missing_df.iterrows(), 1):\n",
    "        fname = row['first_name']\n",
    "        lname = row['second_name']\n",
    "        \n",
    "        print(f\"Debug - name parameter: {name}\")\n",
    "        print(f\"Debug - fname: {fname}, lname: {lname}\")\n",
    "        \n",
    "        if name == \"first\":\n",
    "            filter_name = remove_special_letters(fname)\n",
    "        elif name == \"last\":            \n",
    "            filter_name = remove_special_letters(lname.split(\" \")[-1])\n",
    "        \n",
    "        print(f\"Debug - filter_name: {filter_name}\")\n",
    "        matching_fnames = fbref_df[fbref_df[\"name\"].str.contains(filter_name, case=False, na=False)][\"name\"].tolist()\n",
    "\n",
    "        if matching_fnames:\n",
    "            if level == \"strict\":\n",
    "                related_names = sorted_fuzzy_match(fname if name == \"first\" else lname, matching_fnames)\n",
    "                related_names = [name for name, score in related_names]\n",
    "            if level == \"loose\":\n",
    "                related_names = matching_fnames\n",
    "\n",
    "            print(f\"\\n({i}/{missing_df.shape[0]}) Matching for: {fname} {lname}\")\n",
    "            \n",
    "            for i, (related_name) in enumerate(related_names, 1):\n",
    "                print(f\"{i}. {related_name}\")\n",
    "            \n",
    "            print(\"0. None of the above\")\n",
    "            \n",
    "            choice = input(\"Enter the number of the correct match (0 for none): \")\n",
    "            \n",
    "            if choice.isdigit():\n",
    "                choice = int(choice)\n",
    "                if 1 <= choice <= len(related_names):\n",
    "                    selected_name = related_names[choice - 1][0]\n",
    "                    df.at[idx, \"fuzzy_match\"] = selected_name\n",
    "                    matching_id = fbref_df[fbref_df[\"name\"] == selected_name][\"id\"].iloc[0]\n",
    "                    df.at[idx, \"id_fbref\"] = matching_id\n",
    "                    matched_indices.append(idx)\n",
    "                    print(f\"Selected: {selected_name}\")\n",
    "                \n",
    "                elif choice == 0:\n",
    "                    print(\"No match selected.\")\n",
    "                \n",
    "                else:\n",
    "                    print(\"Invalid choice. No match selected.\")\n",
    "            else:\n",
    "                print(\"Invalid input. No match selected.\")\n",
    "        else:\n",
    "            print(f\"No matches found for {fname} {lname}\")\n",
    "\n",
    "    df.update(df.loc[matched_indices])\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Seasonality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "teams24 = pd.read_csv(\"./data/2024-25/teams.csv\")\n",
    "teams23 = pd.read_csv(\"./data/2023-24/teams.csv\")\n",
    "teams22 = pd.read_csv(\"./data/2022-23/teams.csv\")\n",
    "teams21 = pd.read_csv(\"./data/2021-22/teams.csv\")\n",
    "teams20 = pd.read_csv(\"./data/2020-21/teams.csv\")\n",
    "\n",
    "clubs_link_dict = {\n",
    "\"Liverpool\": \"https://fbref.com/en/squads/822bd0ba/2024-2025/all_comps/Liverpool-Stats-All-Competitions\",\n",
    "\"Man City\": \"https://fbref.com/en/squads/b8fd03ef/2024-2025/all_comps/Manchester-City-Stats-All-Competitions\",\n",
    "\"Arsenal\": \"https://fbref.com/en/squads/18bb7c10/2024-2025/all_comps/Arsenal-Stats-All-Competitions\",\n",
    "\"Chelsea\": \"https://fbref.com/en/squads/cff3d9bb/2024-2025/all_comps/Chelsea-Stats-All-Competitions\",\n",
    "\"Aston Villa\": \"https://fbref.com/en/squads/8602292d/2024-2025/all_comps/Aston-Villa-Stats-All-Competitions\",\n",
    "\"Brighton\": \"https://fbref.com/en/squads/d07537b9/2024-2025/all_comps/Brighton-and-Hove-Albion-Stats-All-Competitions\",\n",
    "\"Newcastle\": \"https://fbref.com/en/squads/b2b47a98/2024-2025/all_comps/Newcastle-United-Stats-All-Competitions\",\n",
    "\"Fulham\": \"https://fbref.com/en/squads/fd962109/2024-2025/all_comps/Fulham-Stats-All-Competitions\",\n",
    "\"Spurs\": \"https://fbref.com/en/squads/361ca564/2024-2025/all_comps/Tottenham-Hotspur-Stats-All-Competitions\",\n",
    "\"Nott'm Forest\": \"https://fbref.com/en/squads/e4a775cb/2024-2025/all_comps/Nottingham-Forest-Stats-All-Competitions\",\n",
    "\"Brentford\": \"https://fbref.com/en/squads/cd051869/2024-2025/all_comps/Brentford-Stats-All-Competitions\",\n",
    "\"West Ham\": \"https://fbref.com/en/squads/7c21e445/2024-2025/all_comps/West-Ham-United-Stats-All-Competitions\",\n",
    "\"Bournemouth\": \"https://fbref.com/en/squads/4ba7cbea/2024-2025/all_comps/Bournemouth-Stats-All-Competitions\",\n",
    "\"Man Utd\": \"https://fbref.com/en/squads/19538871/2024-2025/all_comps/Manchester-United-Stats-All-Competitions\",\n",
    "\"Leicester\": \"https://fbref.com/en/squads/a2d435b3/2024-2025/all_comps/Leicester-City-Stats-All-Competitions\",\n",
    "\"Everton\": \"https://fbref.com/en/squads/d3fd31cc/2024-2025/all_comps/Everton-Stats-All-Competitions\",\n",
    "\"Ipswich\": \"https://fbref.com/en/squads/b74092de/2024-2025/all_comps/Ipswich-Town-Stats-All-Competitions\",\n",
    "\"Crystal Palace\": \"https://fbref.com/en/squads/47c64c55/2024-2025/all_comps/Crystal-Palace-Stats-All-Competitions\",\n",
    "\"Southampton\": \"https://fbref.com/en/squads/33c895d4/2024-2025/all_comps/Southampton-Stats-All-Competitions\",\n",
    "\"Wolves\": \"https://fbref.com/en/squads/8cec06e1/2024-2025/all_comps/Wolverhampton-Wanderers-Stats-All-Competitions\",\n",
    "\"Burnley\": \"https://fbref.com/en/squads/943e8050/2024-2025/all_comps/Burnley-Stats-All-Competitions\",\n",
    "\"Luton\": \"https://fbref.com/en/squads/e297cd13/2024-2025/all_comps/Luton-Town-Stats-All-Competitions\",\n",
    "\"Sheffield Utd\": \"https://fbref.com/en/squads/1df6b87e/2024-2025/all_comps/Sheffield-United-Stats-All-Competitions\",\n",
    "\"Leeds\": \"https://fbref.com/en/squads/5bfb9659/2024-2025/all_comps/Leeds-United-Stats-All-Competitions\",\n",
    "\"Norwich\": \"https://fbref.com/en/squads/1c781004/2024-2025/all_comps/Norwich-City-Stats-All-Competitions\",\n",
    "\"Watford\": \"https://fbref.com/en/squads/2abfe087/2024-2025/all_comps/Watford-Stats-All-Competitions\",\n",
    "\"West Brom\":\"https://fbref.com/en/squads/60c6b05f/2024-2025/all_comps/West-Bromwich-Albion-Stats-All-Competitions\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "team_list24 = teams24[\"name\"].to_list()\n",
    "team_list23 = teams23[\"name\"].to_list()\n",
    "team_list22 = teams22[\"name\"].to_list()\n",
    "team_list21 = teams21[\"name\"].to_list()\n",
    "team_list20 = teams20[\"name\"].to_list()\n",
    "\n",
    "master_team_list = set(team_list24 + team_list23 + team_list22 + team_list21 + team_list20)\n",
    "[x for x in master_team_list if not x in clubs_link_dict.keys()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging Previous fuzzy match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define file paths\n",
    "fbref_path = \"data/2024-25/fbref_ids.csv\"\n",
    "fpl_path = 'data/2024-25/player_idlist.csv'\n",
    "\n",
    "# Load and preprocess data\n",
    "fbref_ids, fpl_ids = load_dfs(fbref_path, fpl_path)\n",
    "\n",
    "# Merge datasets\n",
    "merged = pd.merge(\n",
    "    fpl_ids, \n",
    "    fbref_ids, \n",
    "    \"left\", \n",
    "    on=[\"first_name\", \"second_name\"], \n",
    "    suffixes=[\"_fpl\", \"_fbref\"]\n",
    ")\n",
    "\n",
    "\n",
    "# Get the previous season's data\n",
    "prev_season = \"2023-24\"\n",
    "previous_merged_ids = pd.read_csv(f\"data/{prev_season}/player_compiled_ids.csv\")\n",
    "\n",
    "# Merge the current data with the previous season based on first_name and second_name\n",
    "merged_with_prev = pd.merge(\n",
    "    merged, \n",
    "    previous_merged_ids[[\"first_name_fpl\", \"second_name_fpl\", \"id_fbref\"]], \n",
    "    how=\"left\", \n",
    "    left_on=[\"first_name\", \"second_name\"], \n",
    "    right_on=[\"first_name_fpl\", \"second_name_fpl\"], \n",
    "    suffixes=(\"\", \"_prev\")\n",
    ")\n",
    "\n",
    "# Update the id_fbref in the merged dataframe if it is missing (i.e., NaN) in the current season\n",
    "merged_with_prev[\"id_fbref\"] = merged_with_prev[\"id_fbref\"].combine_first(merged_with_prev[\"id_fbref_prev\"])\n",
    "\n",
    "# Drop the temporary columns used for merging\n",
    "merged_with_prev = merged_with_prev.drop(columns=[\"first_name_fpl\", \"second_name_fpl\", \"id_fbref_prev\"])\n",
    "\n",
    "# Overwrite the merged dataframe with the updated values\n",
    "merged = merged_with_prev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging FBref IDs with previous season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_previous_season(season_str: str) -> str:\n",
    "    # Split the season string into start and end years\n",
    "    start_year = int(season_str[:4])\n",
    "    end_year = int(season_str[5:])\n",
    "    \n",
    "    # Subtract 1 from both years\n",
    "    previous_start_year = start_year - 1\n",
    "    previous_end_year = end_year - 1\n",
    "    \n",
    "    # Format the previous season in \"YYYY-YY\" format\n",
    "    return f\"{previous_start_year}-{str(previous_end_year)[-2:]}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "season = \"2024-25\"\n",
    "\n",
    "# Define file paths\n",
    "fbref_path = f\"./data/{season}/fbref_ids.csv\"\n",
    "fpl_path = f'./data/{season}/player_idlist.csv'\n",
    "\n",
    "# Load and preprocess data\n",
    "fbref_ids, fpl_ids = load_dfs(fbref_path, fpl_path)\n",
    "\n",
    "# Merge datasets\n",
    "merged = pd.merge(\n",
    "    fpl_ids, \n",
    "    fbref_ids, \n",
    "    \"left\", \n",
    "    on=[\"first_name\", \"second_name\"], \n",
    "    suffixes=[\"_fpl\", \"_fbref\"]\n",
    ")\n",
    "\n",
    "\n",
    "    # Get the previous season's data\n",
    "prev_season = get_previous_season(season)\n",
    "previous_merged_ids = pd.read_csv(f\"./data/{prev_season}/player_compiled_ids.csv\")\n",
    "\n",
    "# Merge the current data with the previous season based on first_name and second_name\n",
    "merged_with_prev = pd.merge(\n",
    "    merged, \n",
    "    previous_merged_ids[[\"first_name_fpl\", \"second_name_fpl\", \"id_fbref\"]], \n",
    "    how=\"left\", \n",
    "    left_on=[\"first_name\", \"second_name\"], \n",
    "    right_on=[\"first_name_fpl\", \"second_name_fpl\"], \n",
    "    suffixes=(\"\", \"_prev\")\n",
    ")\n",
    "\n",
    "# Update the id_fbref in the merged dataframe if it is missing (i.e., NaN) in the current season\n",
    "merged_with_prev[\"id_fbref\"] = merged_with_prev[\"id_fbref\"].combine_first(merged_with_prev[\"id_fbref_prev\"])\n",
    "\n",
    "# Drop the temporary columns used for merging\n",
    "merged_with_prev = merged_with_prev.drop(columns=[\"first_name_fpl\", \"second_name_fpl\", \"id_fbref_prev\"])\n",
    "\n",
    "# Overwrite the merged dataframe with the updated values\n",
    "merged = merged_with_prev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data to Send DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       Y\n",
       "1       Y\n",
       "2       Y\n",
       "3       Y\n",
       "4       Y\n",
       "       ..\n",
       "2989    Y\n",
       "2990    Y\n",
       "2991    Y\n",
       "2992    Y\n",
       "2993    Y\n",
       "Name: Captain, Length: 2994, dtype: object"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "season = \"2024-25\"\n",
    "fbref_merged_gw = pd.read_csv(f\"./data/{season}/fbref_merged_gw_data.csv\")\n",
    "\n",
    "fbref_merged_gw[\"Start\"] = fbref_merged_gw[\"Start\"].replace(\"Y*\", \"Y\")\n",
    "fbref_merged_gw[\"Captain\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Day</th>\n",
       "      <th>Comp</th>\n",
       "      <th>Round</th>\n",
       "      <th>Venue</th>\n",
       "      <th>Result</th>\n",
       "      <th>Squad</th>\n",
       "      <th>Opponent</th>\n",
       "      <th>Start</th>\n",
       "      <th>Pos</th>\n",
       "      <th>...</th>\n",
       "      <th>Performance Fls</th>\n",
       "      <th>Performance Fld</th>\n",
       "      <th>Performance Off</th>\n",
       "      <th>Performance Crs</th>\n",
       "      <th>Performance TklW</th>\n",
       "      <th>Performance OG</th>\n",
       "      <th>Performance PKwon</th>\n",
       "      <th>Performance PKcon</th>\n",
       "      <th>Season</th>\n",
       "      <th>Captain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-08-17</td>\n",
       "      <td>Sat</td>\n",
       "      <td>Premier League</td>\n",
       "      <td>1</td>\n",
       "      <td>Home</td>\n",
       "      <td>W 2–0</td>\n",
       "      <td>Arsenal</td>\n",
       "      <td>Wolves</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FW,LM</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-25</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-08-24</td>\n",
       "      <td>Sat</td>\n",
       "      <td>Premier League</td>\n",
       "      <td>2</td>\n",
       "      <td>Away</td>\n",
       "      <td>W 2–0</td>\n",
       "      <td>Arsenal</td>\n",
       "      <td>Aston Villa</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FW</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-25</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-08-31</td>\n",
       "      <td>Sat</td>\n",
       "      <td>Premier League</td>\n",
       "      <td>3</td>\n",
       "      <td>Home</td>\n",
       "      <td>D 1–1</td>\n",
       "      <td>Arsenal</td>\n",
       "      <td>Brighton</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FW</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-25</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-09-15</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Premier League</td>\n",
       "      <td>4</td>\n",
       "      <td>Away</td>\n",
       "      <td>W 1–0</td>\n",
       "      <td>Arsenal</td>\n",
       "      <td>Tottenham</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FW,LM</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-25</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-09-22</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Premier League</td>\n",
       "      <td>5</td>\n",
       "      <td>Away</td>\n",
       "      <td>D 2–2</td>\n",
       "      <td>Arsenal</td>\n",
       "      <td>Manchester City</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RM,FW</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-25</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2989</th>\n",
       "      <td>2024-11-03</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Premier League</td>\n",
       "      <td>10</td>\n",
       "      <td>Home</td>\n",
       "      <td>D 1–1</td>\n",
       "      <td>Manchester Utd</td>\n",
       "      <td>Chelsea</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-25</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2990</th>\n",
       "      <td>2024-10-26</td>\n",
       "      <td>Sat</td>\n",
       "      <td>Premier League</td>\n",
       "      <td>9</td>\n",
       "      <td>Home</td>\n",
       "      <td>D 2–2</td>\n",
       "      <td>Brighton</td>\n",
       "      <td>Wolves</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-25</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2991</th>\n",
       "      <td>2024-10-27</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Premier League</td>\n",
       "      <td>9</td>\n",
       "      <td>Away</td>\n",
       "      <td>D 2–2</td>\n",
       "      <td>Liverpool</td>\n",
       "      <td>Arsenal</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-25</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2992</th>\n",
       "      <td>2024-10-27</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Premier League</td>\n",
       "      <td>9</td>\n",
       "      <td>Away</td>\n",
       "      <td>L 1–2</td>\n",
       "      <td>Manchester Utd</td>\n",
       "      <td>West Ham</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-25</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2993</th>\n",
       "      <td>2024-11-03</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Premier League</td>\n",
       "      <td>10</td>\n",
       "      <td>Home</td>\n",
       "      <td>D 1–1</td>\n",
       "      <td>Manchester Utd</td>\n",
       "      <td>Chelsea</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-25</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2994 rows × 73 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Date  Day            Comp  Round Venue Result           Squad  \\\n",
       "0     2024-08-17  Sat  Premier League      1  Home  W 2–0         Arsenal   \n",
       "1     2024-08-24  Sat  Premier League      2  Away  W 2–0         Arsenal   \n",
       "2     2024-08-31  Sat  Premier League      3  Home  D 1–1         Arsenal   \n",
       "3     2024-09-15  Sun  Premier League      4  Away  W 1–0         Arsenal   \n",
       "4     2024-09-22  Sun  Premier League      5  Away  D 2–2         Arsenal   \n",
       "...          ...  ...             ...    ...   ...    ...             ...   \n",
       "2989  2024-11-03  Sun  Premier League     10  Home  D 1–1  Manchester Utd   \n",
       "2990  2024-10-26  Sat  Premier League      9  Home  D 2–2        Brighton   \n",
       "2991  2024-10-27  Sun  Premier League      9  Away  D 2–2       Liverpool   \n",
       "2992  2024-10-27  Sun  Premier League      9  Away  L 1–2  Manchester Utd   \n",
       "2993  2024-11-03  Sun  Premier League     10  Home  D 1–1  Manchester Utd   \n",
       "\n",
       "             Opponent  Start    Pos  ...  Performance Fls  Performance Fld  \\\n",
       "0              Wolves    NaN  FW,LM  ...              NaN              NaN   \n",
       "1         Aston Villa    NaN     FW  ...              NaN              NaN   \n",
       "2            Brighton    NaN     FW  ...              NaN              NaN   \n",
       "3           Tottenham    NaN  FW,LM  ...              NaN              NaN   \n",
       "4     Manchester City    NaN  RM,FW  ...              NaN              NaN   \n",
       "...               ...    ...    ...  ...              ...              ...   \n",
       "2989          Chelsea    NaN    NaN  ...              NaN              NaN   \n",
       "2990           Wolves    NaN    NaN  ...              NaN              NaN   \n",
       "2991          Arsenal    NaN    NaN  ...              NaN              NaN   \n",
       "2992         West Ham    NaN    NaN  ...              NaN              NaN   \n",
       "2993          Chelsea    NaN    NaN  ...              NaN              NaN   \n",
       "\n",
       "      Performance Off  Performance Crs  Performance TklW  Performance OG  \\\n",
       "0                 NaN              NaN               NaN             NaN   \n",
       "1                 NaN              NaN               NaN             NaN   \n",
       "2                 NaN              NaN               NaN             NaN   \n",
       "3                 NaN              NaN               NaN             NaN   \n",
       "4                 NaN              NaN               NaN             NaN   \n",
       "...               ...              ...               ...             ...   \n",
       "2989              NaN              NaN               NaN             NaN   \n",
       "2990              NaN              NaN               NaN             NaN   \n",
       "2991              NaN              NaN               NaN             NaN   \n",
       "2992              NaN              NaN               NaN             NaN   \n",
       "2993              NaN              NaN               NaN             NaN   \n",
       "\n",
       "      Performance PKwon  Performance PKcon   Season  Captain  \n",
       "0                   NaN                NaN  2024-25        Y  \n",
       "1                   NaN                NaN  2024-25        Y  \n",
       "2                   NaN                NaN  2024-25        Y  \n",
       "3                   NaN                NaN  2024-25        Y  \n",
       "4                   NaN                NaN  2024-25        Y  \n",
       "...                 ...                ...      ...      ...  \n",
       "2989                NaN                NaN  2024-25        Y  \n",
       "2990                NaN                NaN  2024-25        Y  \n",
       "2991                NaN                NaN  2024-25        Y  \n",
       "2992                NaN                NaN  2024-25        Y  \n",
       "2993                NaN                NaN  2024-25        Y  \n",
       "\n",
       "[2994 rows x 73 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_map = {\"Y\": 1, \"N\": 0}\n",
    "fbref_merged_gw[\"Start\"] = fbref_merged_gw[\"Start\"].replace(\"Y*\", \"Y\")\n",
    "fbref_merged_gw[\"Start\"] = fbref_merged_gw[\"Start\"].map(start_map)\n",
    "\n",
    "fbref_merged_gw.to_csv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fpl-project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
